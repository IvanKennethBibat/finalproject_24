{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torch.profiler\n",
    "import torch.utils.data\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\anaconda3\\envs\\sentimentanalysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Ivan Bibat\n",
    "# L00167791\n",
    "# 27/02/2024\n",
    "#\n",
    "# Reddit Scraper for data collection for sentiment analysis\n",
    "# pip install praw\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset then splitting into training, testing, and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0                 Is it worth getting the iPhone 15?   \n",
      "1  Why is the demand for the iPhone 15 series so ...   \n",
      "2  Has anyone got the base model of the iPhone 15...   \n",
      "3    15 Plus thoughts - back to iPhone after 3 years   \n",
      "4                        Anyone bought iphone 15 pro   \n",
      "\n",
      "                                                text  score  comments  \\\n",
      "0  I've seen a ton of negative reviews:  \\n\\-Easi...     14        42   \n",
      "1  I thought iPhone 13 Pro and 14 Pro series alre...    458       689   \n",
      "2  Also, how's the camera and battery life?\\n\\nfe...     30        92   \n",
      "3  After three long years and handful of android ...    776       401   \n",
      "4  Anyone here with iphone 15 pro facing absolute...     97       298   \n",
      "\n",
      "       submission_date                        cleaned_title  \\\n",
      "0  2023-09-30 15:23:12                     worth get iPhone   \n",
      "1  2023-09-23 11:49:19     demand iPhone   series high year   \n",
      "2  2023-10-09 06:46:41  get base model iPhone /plus thought   \n",
      "3  2023-09-30 07:39:32           plus thought iPhone   year   \n",
      "4  2023-10-17 03:44:46                     buy iphone   pro   \n",
      "\n",
      "                                        cleaned_text text_sentiment_label  \\\n",
      "0  see ton negative review  \\n \\-easily crack tre...             Positive   \n",
      "1  think iPhone   Pro   Pro series pretty high de...             Positive   \n",
      "2  camera battery life \\n\\n feel free share pic c...             Positive   \n",
      "3  long year handful android phone finally iPhone...             Negative   \n",
      "4  iphone   pro face absolutely issue \\n\\n   pro ...             Positive   \n",
      "\n",
      "   text_compound_score title_sentiment_label  title_compound_score  \n",
      "0               0.2500              Positive                0.2263  \n",
      "1               0.9153              Negative               -0.1280  \n",
      "2               0.7845               Neutral                0.0000  \n",
      "3              -0.1953               Neutral                0.0000  \n",
      "4               0.1280               Neutral                0.0000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Loading dataset \n",
    "file = 'data/augmentedredditdata_labelled.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "X = df['cleaned_text'].values\n",
    "y = df['text_sentiment_label'].values\n",
    "\n",
    "# Split data into training and validation sets; 64% training, 16% validation, 20% testing.\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 2, 'Negative': 0, 'Neutral': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "encoded_labels_train = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Save the mapping between original labels and encoded labels\n",
    "label_mapping = {original_label: int_label for original_label, int_label in zip(train_labels, encoded_labels_train)}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Validation Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 2, 'Neutral': 1, 'Negative': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "encoded_labels_valid = label_encoder.fit_transform(val_labels)\n",
    "\n",
    "# Save the mapping between original labels and encoded labels\n",
    "label_mapping = {original_label: int_label for original_label, int_label in zip(val_labels, encoded_labels_valid)}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 2, 'Neutral': 1, 'Negative': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "encoded_labels_test = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "# Save the mapping between original labels and encoded labels\n",
    "label_mapping = {original_label: int_label for original_label, int_label in zip(test_labels, encoded_labels_test)}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to use the roberta-base model for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.40.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# initalise the tokenizer\n",
    "roberta = \"roberta-base\"\n",
    "\n",
    "# initalise the model for sequence classification from cardiffnlp / setting the num_labels to 3 for positive, negative, neutral.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta, num_labels = 3)\n",
    "\n",
    "# initialise the tokenizer using roberta-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define a custom Dataset class for sentiment classification\n",
    "class Sentiment(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize and encode the text using the provided tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        # Return a dictionary which contains the tokenised data and labels\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# labels are defined using the encoded values\n",
    "train_labels = encoded_labels_train\n",
    "val_labels = encoded_labels_valid\n",
    "test_labels = encoded_labels_test\n",
    "\n",
    "# Initalise Sentiment instances for the training, testing and validation data, with a max_length of 128. \n",
    "train_data = Sentiment(train_texts, train_labels, tokenizer, max_len=128)\n",
    "val_data = Sentiment(val_texts, val_labels, tokenizer, max_len=128)\n",
    "test_data = Sentiment(test_texts, test_labels, tokenizer, max_len=128)\n",
    "\n",
    "# Initialise DataLoaders for training, testing and validation data.\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdamW Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\anaconda3\\envs\\sentimentanalysis\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import the AdamW optimizer class from the transformers library\n",
    "from transformers import AdamW\n",
    "\n",
    "# Initialize the AdamW optimizer with the parameters of the model\n",
    "# learning rate (lr) put at 1e-6 using the AdamW model.\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed\n",
      "Validation Loss: 0.7992403092591659 and Validation Accuracy: 0.6440217391304348\n",
      "Epoch 1 completed\n",
      "Validation Loss: 0.6144055788931639 and Validation Accuracy: 0.7051630434782609\n",
      "Epoch 2 completed\n",
      "Validation Loss: 0.5433196658673494 and Validation Accuracy: 0.7984601449275361\n",
      "Epoch 3 completed\n",
      "Validation Loss: 0.4886280479638473 and Validation Accuracy: 0.8220108695652174\n",
      "Epoch 4 completed\n",
      "Validation Loss: 0.4456567673579506 and Validation Accuracy: 0.8206521739130435\n",
      "Epoch 5 completed\n",
      "Validation Loss: 0.43109207632748975 and Validation Accuracy: 0.8274456521739131\n",
      "Epoch 6 completed\n",
      "Validation Loss: 0.41340146829252655 and Validation Accuracy: 0.8410326086956522\n",
      "Epoch 7 completed\n",
      "Validation Loss: 0.400819749287937 and Validation Accuracy: 0.8559782608695652\n",
      "Epoch 8 completed\n",
      "Validation Loss: 0.3828676640987396 and Validation Accuracy: 0.8777173913043478\n",
      "Epoch 9 completed\n",
      "Validation Loss: 0.3739435918953108 and Validation Accuracy: 0.8654891304347826\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "    import torch\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    epoch_list = []\n",
    "    val_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    # Check if CUDA (GPU) is available, and move the model to the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # For loop for the 10 epochs\n",
    "    for epoch in range(10):\n",
    "\n",
    "        model.train()  # Training \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad() \n",
    "            input_ids = batch['input_ids'].to(device)  #moves input ids to the device\n",
    "            attention_mask = batch['attention_mask'].to(device)  #moves attentionmask to the device\n",
    "            labels = batch['labels'].to(device)  #moves labels from batch to device\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # Forward pass\n",
    "            loss = outputs[0]\n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "        print(f'Epoch {epoch} completed')  # prints whenever an epoch is completed in training\n",
    "        \n",
    "        \n",
    "        # Validation\n",
    "        model.eval()  # Evaluation mode to validate the model\n",
    "\n",
    "\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs[0]\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "                \n",
    "\n",
    "                # calculating validation accuracy\n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                accuracy = accuracy_score(labels.cpu(), predictions.cpu())\n",
    "                val_accuracy += accuracy\n",
    "                \n",
    "\n",
    "        val_loss /= len(val_loader)  # calculating average validation loss\n",
    "        val_accuracy /= len(val_loader)  # calculating average validation accuracy\n",
    "\n",
    "        writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/validation', val_accuracy, epoch)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "        epoch_list.append(epoch)\n",
    "        \n",
    "        print(f'Validation Loss: {val_loss} and Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_list, val_accuracy_list, label='Validation Accuracy', marker = 'o')\n",
    "plt.plot(epoch_list, val_loss_list, label='Validation Loss', marker = 'x')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Validation Metrics per Epoch')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Lists to store predicted and true labels\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        # Extend the lists with predicted and true labels\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert encoded predictions back to original labels using the label encoder\n",
    "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
    "true_labels = label_encoder.inverse_transform(all_true_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calculate accuracy using true_labels and predicted_labels\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Generate a classification report using true_labels and predicted_labels\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print('Classification Report: ')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the state dictionary of the model to the specified file\n",
    "torch.save(model.state_dict(), 'models/roBERTa.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimentanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
